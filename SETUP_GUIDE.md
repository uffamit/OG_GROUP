# AgoraMedAI - Setup and Testing Guide

This is a comprehensive healthcare platform with AI-powered voice assistance, real-time appointment booking, emergency alerts, and video consultations.

## Prerequisites

- Node.js 20+ and npm
- Firebase project
- Agora account with:
  - App ID and App Certificate
  - Customer ID and Customer Secret (for Conversational AI)
- OpenAI API key
- Azure Text-to-Speech API key
- Google Gemini API key

## Quick Start

1. **Install Dependencies**
   ```bash
   npm install
   ```

2. **Configure Environment Variables**
   
   Copy `.env.example` to `.env.local`:
   ```bash
   cp .env.example .env.local
   ```
   
   Fill in your API keys and credentials in `.env.local`.

3. **Setup Firestore**
   
   This app uses Firebase Firestore for real-time data sync. Make sure to:
   - Create collections: `appointments` and `alerts`
   - Configure Firestore rules (see `firestore.rules`)
   - Update `src/firebase/config.ts` if needed

4. **Run the Development Server**
   ```bash
   npm run dev
   ```
   
   Open [http://localhost:9002](http://localhost:9002) in your browser.

## Testing Guide

### Phase 1: Sanity Check & Dummy Auth

1. **Run the App**
   - Run `npm run dev`
   - Open http://localhost:9002
   - âœ… Check: Does the app load?
   - âœ… Check console for 404 or Firebase errors

2. **Test Patient Login**
   - Click "Enter as Patient" button
   - âœ… Check: Redirected to `/patient/dashboard`?
   - âœ… Check: Open DevTools â†’ Application â†’ localStorage
   - âœ… Verify: `userRole` key set to `patient`

3. **Test Doctor Login**
   - Open incognito/new browser window
   - Go to http://localhost:9002
   - Click "Enter as Doctor"
   - âœ… Check: Redirected to `/doctor/dashboard`?
   - âœ… Verify: `userRole` key set to `doctor`

### Phase 2: Voice â†’ AI â†’ Firestore Pipeline

1. **Prepare**
   - Patient window: `/patient/dashboard`
   - Open Network tab in DevTools
   - Open Firebase Console â†’ Firestore Database

2. **Test Voice Input (Speech-to-Text)**
   - Click the Voice Orb (microphone icon)
   - âœ… Check: Browser asks for microphone permission?
   - âœ… Check: Orb animates (pulse/glow) while listening?
   - Accept microphone permission and speak

3. **Test AI Intent Parsing**
   - Speak: "Book an appointment for tomorrow at 5 PM"
   - âœ… Check Network Tab: See request to `/api/ai/parse-intent`?
   - âœ… Check: Request payload has `{"transcript": "book an appointment..."}`?
   - âœ… Check: Response is 200 OK?
   - âœ… Check: Response JSON has `{"intent": "bookAppointment", "dateTime": "...", ...}`?

4. **Test Database Write**
   - âœ… Check Firebase Console: New document in `appointments` collection?
   - âœ… Verify fields: `patientId`, `doctorId: "dr-demo-id"`, `appointmentTime`

5. **Test Text Input Fallback**
   - Type in text area: "Book an appointment for 7 PM"
   - Click "Send Command"
   - âœ… Check: Same flow as voice (API call, Firestore write, toast notification)

### Phase 3: Real-Time UI Sync ("Magic")

1. **Prepare**
   - Window 1: Patient dashboard (`/patient/dashboard`)
   - Window 2: Doctor dashboard (`/doctor/dashboard`)
   - Position windows side-by-side

2. **Test Appointment Booking Sync**
   - In Window 1 (Patient): Book an appointment via voice or text
   - âœ… Check Window 1: New appointment card appears instantly in "Upcoming Appointments"?
   - âœ… Check Window 2: New appointment appears instantly in "Appointment Queue" table?

3. **Test Emergency Alert Sync**
   - In Window 1 (Patient): 
     - Say "Help me, I'm having severe chest pain!" OR
     - Click the red Emergency button (bottom-right)
   - âœ… Check Firebase Console: New document in `alerts` collection?
   - âœ… Check Window 2: Red "ðŸ”´ NEW EMERGENCY ALERT" box appears instantly?
   - âœ… Check: Alert shows patient ID and symptoms?

### Phase 4: Agora Video & AI Call

1. **Test Call Entry & Token**
   - In Window 1 (Patient): Click "Join Call" on an appointment
   - âœ… Check: Navigate to `/call/[appointmentId]` page?
   - âœ… Check Network Tab: Successful request to `/api/agora/token`?
   - âœ… Check: Response contains token string?

2. **Test AI Bot Start**
   - When call page loads:
   - âœ… Check Network Tab: Successful request to `/api/agora/start`?
   - âœ… Check: Local video feed appears?

3. **Test Video Stream**
   - âœ… Check: Your camera video shows in "Your video" area?
   - âœ… Check: AI bot joins (shows in remote video or starts transcription)?

4. **Test Call Exit**
   - Click "Leave" button
   - âœ… Check Network Tab: Successful request to `/api/agora/stop`?
   - âœ… Check: Video feed disconnects?
   - âœ… Check: Redirected back to patient dashboard?

### Phase 5: Polish & Feedback

1. **Test Audio Feedback (TTS)**
   - Book an appointment
   - âœ… Check: After toast appears, do you hear the app speak?
   - âœ… Listen: "Your appointment is confirmed for [time]"

2. **Test AI Fallback**
   - Say or type gibberish: "Blah blah shlorp"
   - âœ… Check: AI responds with `intent: "unknown"`?
   - âœ… Check: Toast shows fallback message?
   - âœ… Check: TTS says "Sorry, I didn't understand that command"?

## Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ai/parse-intent/    # Voice command intent parsing
â”‚   â”‚   â””â”€â”€ agora/              # Agora token & bot management
â”‚   â”œâ”€â”€ call/[appointmentId]/   # Video call page
â”‚   â”œâ”€â”€ patient/dashboard/      # Patient dashboard
â”‚   â”œâ”€â”€ doctor/dashboard/       # Doctor dashboard
â”‚   â””â”€â”€ page.tsx                # Landing page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ patient/                # Patient components
â”‚   â”œâ”€â”€ doctor/                 # Doctor components
â”‚   â””â”€â”€ shared/                 # Shared components
â”œâ”€â”€ firebase/                   # Firebase configuration
â”œâ”€â”€ ai/                         # AI flows (Genkit)
â”œâ”€â”€ lib/                        # Utilities and helpers
â””â”€â”€ hooks/                      # React hooks
```

## Key Features

### 1. Voice Assistant
- Browser-based speech recognition
- AI intent parsing (book appointments, emergency)
- Text-to-speech feedback
- Fallback text input

### 2. Real-Time Sync
- Firestore real-time listeners
- Instant updates across patient/doctor dashboards
- No refresh needed

### 3. Emergency Alerts
- Voice-activated: "I have severe chest pain"
- Button-activated: Red emergency button
- Instant notification to doctors

### 4. Video Consultations
- Agora RTC integration
- AI conversational bot
- Join calls from appointments

### 5. Authentication
- Demo localStorage-based auth
- Role-based routing (patient/doctor)

## Troubleshooting

### Voice Recognition Not Working
- Ensure you're using Chrome/Edge (WebKit Speech Recognition)
- Check microphone permissions
- Use text input as fallback

### Firestore Permission Errors
- Check `firestore.rules` configuration
- Ensure collections exist: `appointments`, `alerts`
- Verify Firebase credentials in `config.ts`

### Agora Connection Issues
- Verify all Agora credentials in `.env.local`
- Check CORS settings in Agora dashboard
- Ensure OpenAI and Azure TTS keys are valid

### AI Intent Parsing Errors
- Verify Google Gemini API key
- Check API quotas
- Review Network tab for error details

## Development Commands

```bash
# Run development server
npm run dev

# Run type checking
npm run typecheck

# Build for production
npm run build

# Start production server
npm start

# Run Genkit dev server
npm run genkit:dev
```

## License

MIT
